from app.config import settings
from dataclasses import dataclass
from typing import Literal
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langchain_openai import ChatOpenAI
from langchain.agents.structured_output import ToolStrategy
from langgraph.checkpoint.memory import InMemorySaver


'''
æ ‡å‡†çš„agentåˆ›å»ºå’Œä½¿ç”¨æµç¨‹ï¼š 
1.å®šä¹‰æç¤ºè¯
2.å®šä¹‰å·¥å…·
3.æ„å»ºchat model
4.ç»“æ„åŒ–è¾“å‡º
5.memory
6.åˆ›å»ºagent
'''

# 1.å®šä¹‰æç¤ºè¯
SYSTEM_PROMPT = """ä½ æ˜¯å¤©æ°”åŠ©æ‰‹,å¦‚æœè¢«é—®åˆ°å¤©æ°”é—®é¢˜ï¼Œè¯·å…ˆç¡®å®šåœ°ç‚¹ï¼Œç„¶åè°ƒç”¨ç›¸å…³å·¥å…·è·å–å®é™…å¤©æ°”"""


# 2.å®šä¹‰å·¥å…·

@dataclass
class Context:
    """Custom runtime context schema."""
    user_id: str

@tool
def get_weather_for_location(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”"""
    return f"{city}æ€»æ˜¯æ™´æ—¥"

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """æ ¹æ®ç”¨æˆ·IDè·å–ç”¨æˆ·ä½ç½®"""
    user_id = runtime.context.user_id
    return "åŒ—äº¬" if user_id == "1" else "ä¸Šæµ·"

# 3.æ„å»ºchat model
# ç¬¦åˆopenaiè§„èŒƒçš„api,å¯ä»¥ä½¿ç”¨langchain_openaiã€‚æˆ‘ä»¬ä½¿ç”¨ SiliconFlow æä¾›çš„ GLM-4.7 æ¨¡å‹
# æ³¨æ„ï¼šå°½é‡ä½¿ç”¨ä¸€äº›æ–°æ¨¡å‹ï¼Œä¸€äº›æ—§æ¨¡å‹å¯èƒ½ä¼šå­˜åœ¨ä¸€äº›ç‰¹æ€§ä¸æ”¯æŒ
model = ChatOpenAI(
    model=settings.glm_model,
    base_url=settings.siliconflow_base_url,
    api_key=settings.siliconflow_api_key,
    temperature=0.9,
    max_tokens=5000,
    timeout=60,
)

# 4.ç»“æ„åŒ–è¾“å‡º
# dataclass å’Œ Pydantic éƒ½æ˜¯æ”¯æŒçš„ï¼Œç”¨æ¥å®šä¹‰ç»“æ„åŒ–è¾“å‡ºçš„æ ¼å¼ã€‚
@dataclass
class ResponseFormat:
    """agentçš„å“åº”æ ¼å¼"""
    # ä¸€è¯­åŒå…³çš„å›ç­” (å¿…è¦)
    punny_response: str
    # å’Œå¤©æ°”ç›¸å…³çš„ä¿¡æ¯ç‚¹ï¼ˆå¯é€‰ï¼‰
    weather_conditions: str | None = None
    # å­—ç¬¦ä¸²ï¼Œç”¨äºæè¿°å“åº”çš„é•¿åº¦ï¼Œå–å€¼ä¸º"short"ã€"medium"ã€"long"ä¹‹ä¸€
    length: Literal["short", "medium", "long"] = "short"

# 5.memory
checkpointer = InMemorySaver()


# 6.åˆ›å»ºagent
agent = create_agent(
    model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(ResponseFormat),
    checkpointer=checkpointer,
    # debug=True, # å¼€å¯debugæ¨¡å¼ï¼Œä¼šæ‰“å°å‡ºagentçš„è¿è¡Œè¿‡ç¨‹
)

# `thread_id`ä¸€æ¬¡ä¼šè¯çš„å”¯ä¸€æ ‡è¯†ç¬¦
config = {"configurable": {"thread_id": "1"}}

response = agent.invoke(
    {"messages": [{"role": "user", "content": "ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
    config=config,
    context=Context(user_id="1")
)

print(response['structured_response'])
# ResponseFormat(punny_response='ä»Šå¤©çš„å¤©æ°”æ™´æœ—æ¸©æš–ï¼Œé˜³å…‰æ˜åªšï¼Œç»å¯¹æ˜¯ä¸€ä¸ªå‡ºå»èµ°èµ°çš„å¥½æ—¥å­ï¼â˜€ï¸', weather_conditions='æ™´æ—¥', length='medium')

# æ³¨æ„ï¼šæˆ‘ä»¬å¯ä»¥ç”¨åŒä¸€ä¸ª`thread_id`ç»§ç»­è¿™ä¸ªå¯¹è¯.
response = agent.invoke(
    {"messages": [{"role": "user", "content": "thank you!"}]},
    config=config,
    context=Context(user_id="1")
)

print(response['structured_response'])
# ResponseFormat(punny_response='ä¸ç”¨å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¸®åˆ°ä½ ï¼å¸Œæœ›ä½ ä»Šå¤©æœ‰ä¸ªæ™´æœ—æ„‰å¿«çš„ä¸€å¤©ï¼â˜€ï¸ğŸ˜Š', weather_conditions=None, length='medium')